{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab835a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf7bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "icbhi_path = 'ICBHI_final_database'\n",
    "audio_files = [f for f in os.listdir(icbhi_path) if f.endswith('.wav')]\n",
    "\n",
    "random.seed(42)  \n",
    "selected_icbhi_files = random.sample([f for f in audio_files], 5)\n",
    "\n",
    "def preprocess_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    audio = librosa.util.normalize(audio)\n",
    "    return audio, sr\n",
    "\n",
    "icbhi_data = [preprocess_audio(os.path.join(icbhi_path, f)) for f in selected_icbhi_files]\n",
    "\n",
    "print('Selected ICBHI files:')\n",
    "for f in selected_icbhi_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52424ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/iiscleap/Coswara-Data.git\n",
    "coswara_path = 'Coswara-Data'\n",
    "\n",
    "def get_wav_files(directory):\n",
    "    wav_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                wav_files.append(os.path.join(root, file))\n",
    "    return wav_files\n",
    "\n",
    "coswara_files = get_wav_files(coswara_path)\n",
    "\n",
    "selected_coswara_files = random.sample(coswara_files, 5)\n",
    "\n",
    "def filter_and_preprocess(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    if len(audio) > sr:\n",
    "        audio = librosa.util.normalize(audio)\n",
    "        return audio, sr\n",
    "    return None\n",
    "\n",
    "coswara_data = [filter_and_preprocess(f) for f in selected_coswara_files if filter_and_preprocess(f) is not None]\n",
    "\n",
    "print('\\nSelected Coswara files:')\n",
    "for f in selected_coswara_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_audio(audio, sr):\n",
    "    \n",
    "    augmented = []\n",
    "    pitch_shifts = [-2, -1, 1, 2]\n",
    "    for steps in pitch_shifts:\n",
    "        augmented.append(librosa.effects.pitch_shift(audio, sr=sr, n_steps=steps))\n",
    "    \n",
    "    stretch_rates = [0.8, 0.9, 1.1, 1.2]\n",
    "    for rate in stretch_rates:\n",
    "        augmented.append(librosa.effects.time_stretch(audio, rate=rate))\n",
    "    \n",
    "    noise_levels = [0.005, 0.01, 0.02]\n",
    "    for level in noise_levels:\n",
    "        augmented.append(audio + level * np.random.randn(len(audio)))\n",
    "    return augmented\n",
    "\n",
    "augmented_icbhi = []\n",
    "for audio, sr in icbhi_data:\n",
    "    augmented_icbhi.extend([(aug, sr) for aug in augment_audio(audio, sr)])\n",
    "\n",
    "augmented_coswara = []\n",
    "for audio, sr in coswara_data:\n",
    "    augmented_coswara.extend([(aug, sr) for aug in augment_audio(audio, sr)])\n",
    "\n",
    "print(f'Original ICBHI samples: {len(icbhi_data)}')\n",
    "print(f'Augmented ICBHI samples: {len(augmented_icbhi)}')\n",
    "print(f'Original Coswara samples: {len(coswara_data)}')\n",
    "print(f'Augmented Coswara samples: {len(augmented_coswara)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f6a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def extract_mel_spectrogram(audio, sr):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=8000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "print('Extracting features from ICBHI dataset...')\n",
    "icbhi_specs = [extract_mel_spectrogram(audio, sr) for audio, sr in tqdm(icbhi_data + augmented_icbhi)]\n",
    "\n",
    "print('\\nExtracting features from Coswara dataset...')\n",
    "coswara_specs = [extract_mel_spectrogram(audio, sr) for audio, sr in tqdm(coswara_data + augmented_coswara)]\n",
    "\n",
    "mel_spectrograms = icbhi_specs + coswara_specs\n",
    "print(f'\\nTotal number of processed samples: {len(mel_spectrograms)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280dc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, None, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.RepeatVector(10),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(5, activation='softmax') \n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b041dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.random.rand(100, 128, 500, 1), np.random.randint(0, 5, (100, 5))  \n",
    "X_val, y_val = np.random.rand(20, 128, 500, 1), np.random.randint(0, 5, (20, 5)) \n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934bc1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = np.random.rand(20, 128, 500, 1), np.random.randint(0, 5, (20, 5))  \n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e99eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "   \n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'])\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c693373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mel_spectrogram(mel_spec, title='Mel Spectrogram'):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(mel_spec, y_axis='mel', x_axis='time', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d41e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], \n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "    \n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    \n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(y_true, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)\n",
    "\n",
    "if len(mel_spectrograms) > 0:\n",
    "    plot_mel_spectrogram(mel_spectrograms[0], 'Sample Lung Sound Mel Spectrogram')\n",
    "\n",
    "sample_input = X_test[0:1]\n",
    "heatmap = make_gradcam_heatmap(sample_input, model, 'conv2d_2')\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(heatmap, cmap='viridis')\n",
    "plt.title('Grad-CAM Visualization')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
