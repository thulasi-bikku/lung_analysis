{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Lung Disease Prediction using Deep Learning\n",
    "Implementation of an AI-driven early detection system for respiratory diseases using lung sound analysis. This notebook implements a CNN-RNN fusion model for classifying different respiratory conditions."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": ["# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Data Loading and Preprocessing\n",
    "First, we'll implement the data preprocessing steps including:\n",
    "1. Loading the ICBHI dataset\n",
    "2. Applying high-pass filtering\n",
    "3. Segmenting recordings into 2.5s frames\n",
    "4. Converting to Mel-spectrograms"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": ["class DataLoader:\n",
    "    def __init__(self, data_dir: str, sr: int = 22050):\n",
    "        \"\"\"Initialize DataLoader\n",
    "        Args:\n",
    "            data_dir: Directory containing the dataset\n",
    "            sr: Sampling rate for audio processing\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.sr = sr\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def load_icbhi_dataset(self) -> Tuple[List[np.ndarray], List[str]]:\n",
    "        \"\"\"Load ICBHI dataset\n",
    "        Returns:\n",
    "            Tuple of (audio_data, labels)\n",
    "        \"\"\"\n",
    "        audio_data = []\n",
    "        labels = []\n",
    "        \n",
    "        # Load and process audio files\n",
    "        for file in os.listdir(self.data_dir):\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(self.data_dir, file)\n",
    "                # Load and preprocess audio\n",
    "                audio = self.preprocess_audio(file_path)\n",
    "                audio_data.append(audio)\n",
    "                \n",
    "                # Extract label from filename or annotation file\n",
    "                label = self._get_label(file)\n",
    "                labels.append(label)\n",
    "        \n",
    "        return audio_data, labels\n",
    "    \n",
    "    def preprocess_audio(self, file_path: str) -> np.ndarray:\n",
    "        \"\"\"Preprocess audio file\n",
    "        Args:\n",
    "            file_path: Path to audio file\n",
    "        Returns:\n",
    "            Preprocessed audio signal\n",
    "        \"\"\"\n",
    "        # Load audio\n",
    "        y, _ = librosa.load(file_path, sr=self.sr)\n",
    "        \n",
    "        # Apply high-pass filter\n",
    "        y_filtered = librosa.effects.high_pass_filter(y, sr=self.sr, cutoff=20)\n",
    "        \n",
    "        # Normalize\n",
    "        y_normalized = self.scaler.fit_transform(y_filtered.reshape(-1, 1)).ravel()\n",
    "        \n",
    "        return y_normalized\n",
    "    \n",
    "    def segment_audio(self, y: np.ndarray, segment_length: float = 2.5, \n",
    "                      overlap: float = 0.5) -> List[np.ndarray]:\n",
    "        \"\"\"Segment audio into overlapping frames\n",
    "        Args:\n",
    "            y: Audio signal\n",
    "            segment_length: Length of each segment in seconds\n",
    "            overlap: Overlap between segments (0-1)\n",
    "        Returns:\n",
    "            List of segments\n",
    "        \"\"\"\n",
    "        samples_per_segment = int(segment_length * self.sr)\n",
    "        hop_length = int(samples_per_segment * (1 - overlap))\n",
    "        \n",
    "        segments = []\n",
    "        for i in range(0, len(y) - samples_per_segment + 1, hop_length):\n",
    "            segment = y[i:i + samples_per_segment]\n",
    "            segments.append(segment)\n",
    "        \n",
    "        return segments\n",
    "    \n",
    "    def extract_features(self, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Extract features from audio signal\n",
    "        Args:\n",
    "            y: Audio signal\n",
    "        Returns:\n",
    "            Feature matrix\n",
    "        \"\"\"\n",
    "        # Create mel-spectrogram\n",
    "        mel_spect = librosa.feature.melspectrogram(\n",
    "            y=y,\n",
    "            sr=self.sr,\n",
    "            n_mels=128,\n",
    "            fmax=self.sr/2\n",
    "        )\n",
    "        \n",
    "        # Convert to log scale\n",
    "        mel_spect_db = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "        \n",
    "        # Extract MFCCs\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=self.sr, n_mfcc=13)\n",
    "        \n",
    "        # Extract zero crossing rate\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        \n",
    "        # Combine features\n",
    "        features = np.vstack([mel_spect_db, mfccs, zcr])\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _get_label(self, filename: str) -> str:\n",
    "        \"\"\"Extract label from filename or annotation file\n",
    "        Args:\n",
    "            filename: Audio filename\n",
    "        Returns:\n",
    "            Label string\n",
    "        \"\"\"\n",
    "        # Implement label extraction logic based on dataset structure\n",
    "        # This is a placeholder - modify according to actual dataset\n",
    "        if 'crackle' in filename.lower():\n",
    "            return 'pneumonia'\n",
    "        elif 'wheeze' in filename.lower():\n",
    "            return 'asthma'\n",
    "        else:\n",
    "            return 'normal'"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Model Architecture\n",
    "Implementation of the CNN-RNN fusion model for lung sound classification"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": ["class LungSoundModel:\n",
    "    def __init__(self, input_shape: Tuple[int, int, int]):\n",
    "        \"\"\"Initialize the CNN-RNN fusion model\n",
    "        Args:\n",
    "            input_shape: Shape of input data (time_steps, features, channels)\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self._build_model()\n",
    "    \n",
    "    def _build_model(self) -> models.Model:\n",
    "        \"\"\"Build the CNN-RNN fusion model architecture\n",
    "        Returns:\n",
    "            Compiled Keras model\n",
    "        \"\"\"\n",
    "        # Input layer\n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # CNN layers\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        \n",
    "        # Reshape for RNN\n",
    "        x = layers.Reshape((-1, x.shape[-1] * x.shape[-2]))(x)\n",
    "        \n",
    "        # RNN layers\n",
    "        x = layers.LSTM(128, return_sequences=True)(x)\n",
    "        x = layers.LSTM(64)(x)\n",
    "        \n",
    "        # Dense layers\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        \n",
    "        # Output layer\n",
    "        outputs = layers.Dense(4, activation='softmax')(x)  # 4 classes: normal, pneumonia, asthma, COPD\n",
    "        \n",
    "        # Create model\n",
    "        model = models.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, x_train, y_train, x_val, y_val, epochs=50, batch_size=32):\n",
    "        \"\"\"Train the model\n",
    "        Args:\n",
    "            x_train: Training data\n",
    "            y_train: Training labels\n",
    "            x_val: Validation data\n",
    "            y_val: Validation labels\n",
    "            epochs: Number of training epochs\n",
    "            batch_size: Batch size for training\n",
    "        Returns:\n",
    "            Training history\n",
    "        \"\"\"\n",
    "        history = self.model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            validation_data=(x_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Make predictions\n",
    "        Args:\n",
    "            x: Input data\n",
    "        Returns:\n",
    "            Predicted probabilities\n",
    "        \"\"\"\n",
    "        return self.model.predict(x)\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        \"\"\"Evaluate model performance\n",
    "        Args:\n",
    "            x_test: Test data\n",
    "            y_test: Test labels\n",
    "        Returns:\n",
    "            Test loss and metrics\n",
    "        \"\"\"\n",
    "        return self.model.evaluate(x_test, y_test)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Training Pipeline\n",
    "Set up the training pipeline and train the model"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": ["# Initialize data loader\n",
    "data_loader = DataLoader('path/to/dataset')\n",
    "\n",
    "# Load and preprocess data\n",
    "audio_data, labels = data_loader.load_icbhi_dataset()\n",
    "\n",
    "# Process each audio file\n",
    "processed_data = []\n",
    "for audio in audio_data:\n",
    "    # Segment audio\n",
    "    segments = data_loader.segment_audio(audio)\n",
    "    \n",
    "    # Extract features for each segment\n",
    "    segment_features = [data_loader.extract_features(segment) for segment in segments]\n",
    "    processed_data.extend(segment_features)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(processed_data)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train model\n",
    "model = LungSoundModel(input_shape=X_train.shape[1:])\n",
    "history = model.train(X_train, y_train, X_val, y_val)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Model Evaluation\n",
    "Evaluate model performance and visualize results"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": ["# Evaluate model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}